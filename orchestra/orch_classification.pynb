{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import madmom\n",
    "import myutils\n",
    "import collections\n",
    "import subprocess\n",
    "from os.path import basename\n",
    "import librosa\n",
    "\n",
    "from essentia import *\n",
    "from essentia.standard import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['strings', 'woodwind', 'brass', 'percussion']\n",
      "['strings/cello', 'strings/violin', 'strings/viola', 'strings/double_bass', 'woodwind/bassoon', 'woodwind/clarinet', 'woodwind/oboe', 'woodwind/flute', 'brass/french_horn', 'brass/trombone', 'brass/trumpet', 'brass/tuba', 'percussion/percussion']\n"
     ]
    }
   ],
   "source": [
    "# datasetPath = \"samples/\"\n",
    "datasetPath = \"/Users/carthach/tmp/general_timbre/selection2/\"\n",
    "\n",
    "#Get the timbreClasses in datasetPath\n",
    "timbreClasses = [d for d in os.listdir(datasetPath) if os.path.isdir(os.path.join(datasetPath, d))]\n",
    "\n",
    "instrumentClasses = []\n",
    "\n",
    "for timbreClass in timbreClasses:\n",
    "    instrumentPath = datasetPath + timbreClass\n",
    "    sectionInstrumentClasses = [d for d in os.listdir(instrumentPath) if os.path.isdir(os.path.join(instrumentPath, d))]\n",
    "    sectionInstrumentClasses = [\"%s/%s\" % (timbreClass, sectionInstrumentClass) for sectionInstrumentClass in sectionInstrumentClasses]\n",
    "    \n",
    "    instrumentClasses += sectionInstrumentClasses\n",
    "\n",
    "print timbreClasses\n",
    "print instrumentClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poolToVector(pool):\n",
    "    featureVector = []\n",
    "    \n",
    "    for feature in pool.descriptorNames():\n",
    "        if isinstance(pool[feature], (list, tuple, np.ndarray)):\n",
    "            for featureScalar in pool[feature]:\n",
    "                featureVector.append(featureScalar)\n",
    "        else:\n",
    "            featureVector.append(pool[feature])\n",
    "                                        \n",
    "    return featureVector\n",
    "\n",
    "def savePool(filename, pool):\n",
    "    YamlOutput(filename = filename, writeVersion=False)(pool)\n",
    "    \n",
    "def loadPool(filename):\n",
    "    yamlInput = YamlInput(filename=filename)\n",
    "    \n",
    "    pool = yamlInput()\n",
    "    \n",
    "    return pool\n",
    "\n",
    "def extractFeatures(filename):\n",
    "    audio, sampleRate = librosa.load(filename, sr=44100)\n",
    "#     audio, sampleRate = loadAudio(filename)\n",
    "\n",
    "    # create the pool and the necessary algorithms\n",
    "    pool = Pool()\n",
    "    w = Windowing()\n",
    "    spec = Spectrum()\n",
    "    centroid = Centroid(range=22050)\n",
    "    flatness = Flatness()\n",
    "    flatnessDB = FlatnessDB()\n",
    "    mfcc = MFCC()\n",
    "    bfcc = BFCC(\n",
    "        type = 'power',\n",
    "        weighting = 'linear',\n",
    "        lowFrequencyBound = 0,\n",
    "        highFrequencyBound = 22050,\n",
    "        numberBands = 26,\n",
    "        numberCoefficients = 13,\n",
    "        normalize = 'unit_max',\n",
    "        dctType = 3,\n",
    "        liftering = 22\n",
    "    )\n",
    "    loudness = Loudness()\n",
    "    logAttackTime = LogAttackTime()\n",
    "        \n",
    "    # compute the centroid for all frames in our audio and add it to the pool\n",
    "    for frame in FrameGenerator(audio, frameSize = 1024, hopSize = 512):        \n",
    "        s = spec(w(frame))\n",
    "        \n",
    "        c = centroid(s)\n",
    "        pool.add('centroid', c)\n",
    "        \n",
    "#         f = flatness(s)\n",
    "        f = flatnessDB(s)        \n",
    "        pool.add('flatness', f)        \n",
    "\n",
    "        m_bands, m_coeffs = mfcc(s)\n",
    "        pool.add('mfcc', m_coeffs)\n",
    "        \n",
    "        b_bands, b_coeffs = bfcc(s)\n",
    "        pool.add('bfcc', b_coeffs)\n",
    "        \n",
    "    # aggregate the results\n",
    "    aggrPool = PoolAggregator(defaultStats = [ 'mean', 'var'])(pool)\n",
    "    \n",
    "    l, aStart, aStop = logAttackTime(audio)\n",
    "    aggrPool.add('logAttackTime', l)\n",
    "    aggrPool.add('loudness', loudness(audio))\n",
    "    \n",
    "    return aggrPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def analyseSounds(datasetPath, soundClasses, reAnalyse=False, featureSet=[]):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for soundClass in soundClasses:\n",
    "        soundPath = datasetPath + soundClass\n",
    "\n",
    "        soundFiles = myutils.getListOfFilesRecursive(soundPath, \"*.mp3\")\n",
    "    \n",
    "        print \"Processing: %s\" % soundClass\n",
    "    \n",
    "        for soundFile in soundFiles:\n",
    "            yamlFile = soundFile + \".yaml\"\n",
    "            \n",
    "            #Analyse or retrieve yaml features\n",
    "            if not os.path.isfile(yamlFile) or reAnalyse:            \n",
    "                featurePool = extractFeatures(soundFile)\n",
    "                savePool(yamlFile, featurePool)\n",
    "            else:        \n",
    "                featurePool = loadPool(yamlFile)\n",
    "                \n",
    "            for descriptor in featurePool.descriptorNames():\n",
    "                if descriptor not in featureSet:\n",
    "                    featurePool.remove(descriptor)\n",
    "                                                        \n",
    "            featureVector = poolToVector(featurePool)\n",
    "                    \n",
    "#             print featureVector\n",
    "#             print(\"\\n*********************\")\n",
    "                    \n",
    "#             timbreFeatureDict[timbreClass][timbreClassFile] = features\n",
    "\n",
    "            features.append(featureVector)\n",
    "            labels.append(soundClasses.index(soundClass))  \n",
    "        \n",
    "#             print \"\\t%s\" % soundFile\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "temporalFeatures = [\"loudness\", \"logAttackTime\"]\n",
    "spectralFeatures = [\"centroid.mean\", \"centroid.var\", \"flatness.mean\", \"flatness.var\"]\n",
    "mfccFeatures = [\"mfcc.mean\", \"mfcc.var\"]\n",
    "bfccFeatures = [\"bfcc.mean\", \"bfcc.var\"]\n",
    "temporalSpectralFeatures = temporalFeatures + spectralFeatures\n",
    "mfccTemporalSpectralFeatures = mfccFeatures + temporalSpectralFeatures\n",
    "bfccTemporalSpectralFeatures = bfccFeatures + temporalSpectralFeatures\n",
    "\n",
    "featureSets = {\n",
    "    \"Temporal\" : temporalFeatures,\n",
    "    \"Spectral\" : spectralFeatures,\n",
    "    \"Temporal+Spectral\" : temporalSpectralFeatures,\n",
    "    \"MFCC\" : mfccFeatures,\n",
    "    \"BFCC\" : bfccFeatures,\n",
    "    \"MFCC+Temporal+Spectral\" : mfccTemporalSpectralFeatures,\n",
    "    \"BFCC+Temporal+Spectral\" : bfccTemporalSpectralFeatures\n",
    "}\n",
    "\n",
    "# features, labels = analyseSounds(datasetPath, instrumentClasses, reAnalyse=True, featureSet=featureSet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Spectral\n",
      "Processing: strings\n",
      "Processing: woodwind\n",
      "Processing: brass\n",
      "Processing: percussion\n",
      "Classifying with: kNN\n",
      "0.58 (+/- 0.07)\n",
      "Classifying with: SVM\n",
      "0.59 (+/- 0.24)\n",
      "Classifying with: ANN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 (+/- 0.15)\n",
      "Evaluating: MFCC\n",
      "Processing: strings\n",
      "Processing: woodwind\n",
      "Processing: brass\n",
      "Processing: percussion\n",
      "Classifying with: kNN\n",
      "0.85 (+/- 0.09)\n",
      "Classifying with: SVM\n",
      "0.82 (+/- 0.12)\n",
      "Classifying with: ANN\n",
      "0.86 (+/- 0.11)\n",
      "Evaluating: Temporal\n",
      "Processing: strings\n",
      "Processing: woodwind\n",
      "Processing: brass\n",
      "Processing: percussion\n",
      "Classifying with: kNN\n",
      "0.36 (+/- 0.12)\n",
      "Classifying with: SVM\n",
      "0.45 (+/- 0.14)\n",
      "Classifying with: ANN\n",
      "0.52 (+/- 0.17)\n",
      "Evaluating: BFCC+Temporal+Spectral\n",
      "Processing: strings\n",
      "Processing: woodwind\n",
      "Processing: brass\n",
      "Processing: percussion\n",
      "Classifying with: kNN\n",
      "0.86 (+/- 0.08)\n",
      "Classifying with: SVM\n",
      "0.89 (+/- 0.08)\n",
      "Classifying with: ANN\n",
      "0.90 (+/- 0.06)\n",
      "Evaluating: BFCC\n",
      "Processing: strings\n",
      "Processing: woodwind\n",
      "Processing: brass\n",
      "Processing: percussion\n",
      "Classifying with: kNN\n",
      "0.83 (+/- 0.11)\n",
      "Classifying with: SVM\n",
      "0.83 (+/- 0.12)\n",
      "Classifying with: ANN\n",
      "0.86 (+/- 0.10)\n",
      "Evaluating: MFCC+Temporal+Spectral\n",
      "Processing: strings\n",
      "Processing: woodwind\n",
      "Processing: brass\n",
      "Processing: percussion\n",
      "Classifying with: kNN\n",
      "0.86 (+/- 0.06)\n",
      "Classifying with: SVM\n",
      "0.86 (+/- 0.08)\n",
      "Classifying with: ANN\n",
      "0.87 (+/- 0.07)\n",
      "Evaluating: Temporal+Spectral\n",
      "Processing: strings\n",
      "Processing: woodwind\n",
      "Processing: brass\n",
      "Processing: percussion\n",
      "Classifying with: kNN\n",
      "0.66 (+/- 0.15)\n",
      "Classifying with: SVM\n",
      "0.66 (+/- 0.18)\n",
      "Classifying with: ANN\n",
      "0.68 (+/- 0.17)\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import csv\n",
    "\n",
    "reAnalyse = False\n",
    "\n",
    "with open('results.csv', 'wb') as csvfile:\n",
    "    resultswriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    resultswriter.writerow([\"\", \"kNN\", \"SVM\", \"ANN\"])    \n",
    "    \n",
    "    for featureSetName, featureSet in featureSets.iteritems():\n",
    "        print(\"Evaluating: %s\" % featureSetName)\n",
    "        \n",
    "        features, labels = analyseSounds(datasetPath, timbreClasses, reAnalyse=reAnalyse, featureSet=featureSet)\n",
    "\n",
    "        if reAnalyse:\n",
    "            reAnalyse = False\n",
    "        \n",
    "    #     print features\n",
    "\n",
    "\n",
    "\n",
    "        classifierNames = [\"kNN\", \"SVM\", \"ANN\"]\n",
    "\n",
    "        classifiers = [KNeighborsClassifier(1),\n",
    "                       SVC(gamma=0.1, C=100.),\n",
    "                       MLPClassifier(max_iter=500)\n",
    "                      ]\n",
    "        \n",
    "        results = []\n",
    "\n",
    "        # iterate over classifiers        \n",
    "        for classifierName, clf in zip(classifierNames, classifiers):\n",
    "            if classifierName == \"ANN\":\n",
    "                scaler = StandardScaler()\n",
    "            else:\n",
    "                scaler = MinMaxScaler()\n",
    "                \n",
    "            features = scaler.fit_transform(features)\n",
    "\n",
    "            n_samples = len(features)\n",
    "            n_features = len(features[0])\n",
    "            n_units = n_features\n",
    "            \n",
    "            print(\"Classifying with: %s\" % classifierName)\n",
    "            scores = cross_val_score(clf, features, labels, cv=10)\n",
    "            result = \"%0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)\n",
    "            print(result)\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        resultswriter.writerow([featureSetName, results[0], results[1], results[2]])\n",
    "        \n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_neural_net(ax, left, right, bottom, top, layer_sizes,\n",
    "coefs_, \n",
    "intercepts_,\n",
    "n_iter_, \n",
    "loss_, \n",
    "np, plt):\n",
    "    '''\n",
    "    Draw a neural network cartoon using matplotilb.\n",
    "\n",
    "    :usage:\n",
    "        >>> fig = plt.figure(figsize=(12, 12))\n",
    "        >>> draw_neural_net(fig.gca(), .1, .9, .1, .9, [4, 7, 2])\n",
    "\n",
    "    :parameters:\n",
    "        - ax : matplotlib.axes.AxesSubplot\n",
    "            The axes on which to plot the cartoon (get e.g. by plt.gca())\n",
    "        - left : float\n",
    "            The center of the leftmost node(s) will be placed here\n",
    "        - right : float\n",
    "            The center of the rightmost node(s) will be placed here\n",
    "        - bottom : float\n",
    "            The center of the bottommost node(s) will be placed here\n",
    "        - top : float\n",
    "            The center of the topmost node(s) will be placed here\n",
    "        - layer_sizes : list of int\n",
    "            List of layer sizes, including input and output dimensionality\n",
    "        - coefs_ :(list) length (n_layers - 1) The ith element in the list represents the weight matrix corresponding to layer i.\n",
    "        - intercepts_ : (list) length (n_layers - 1)The ith element in the list represents the bias vector corresponding to layer i + 1.\n",
    "        - n_iter_ : (int) The number of iterations the solver has ran.\n",
    "        - loss_ : (float) The current loss computed with the loss function.\n",
    "    '''\n",
    "    n_layers = len(layer_sizes)\n",
    "    v_spacing = (top - bottom)/float(max(layer_sizes))\n",
    "    h_spacing = (right - left)/float(len(layer_sizes) - 1)\n",
    "    # Input-Arrows\n",
    "    layer_top_0 = v_spacing*(layer_sizes[0] - 1)/2. + (top + bottom)/2.\n",
    "    for m in xrange(layer_sizes[0]):\n",
    "        plt.arrow(left-0.15, layer_top_0 - m*v_spacing, 0.10, 0,  lw =1, head_width=0.01, head_length=0.02)\n",
    "    # Nodes\n",
    "    for n, layer_size in enumerate(layer_sizes):\n",
    "        layer_top = v_spacing*(layer_size - 1)/2. + (top + bottom)/2.\n",
    "        for m in xrange(layer_size):\n",
    "            circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/4.,color='w', ec='k', zorder=4)\n",
    "#             plt.plot(n*h_spacing + left, layer_top - m*v_spacing, 'o', mfc='w', mec='k', ls= '-', markersize = 40)\n",
    "\n",
    "    # Add texts\n",
    "            if n == 0:\n",
    "                plt.text(left-0.125, layer_top - m*v_spacing, r'$X_{'+str(m+1)+'}$', fontsize=15)\n",
    "            elif (n_layers == 3) & (n == 1):\n",
    "                plt.text(n*h_spacing + left+0.00, layer_top - m*v_spacing+ (v_spacing/8.+0.01*v_spacing), r'$H_{'+str(m+1)+'}$', fontsize=15)\n",
    "            elif n == n_layers -1:\n",
    "                plt.text(n*h_spacing + left+0.10, layer_top - m*v_spacing, r'$y_{'+str(m+1)+'}$', fontsize=15)\n",
    "            ax.add_artist(circle)# \n",
    "    # Bias-Nodes\n",
    "    for n, layer_size in enumerate(layer_sizes):\n",
    "        if n < n_layers -1:\n",
    "            x_bias = (n+0.5)*h_spacing + left\n",
    "            y_bias = top + 0.005\n",
    "            circle = plt.Circle((x_bias, y_bias), v_spacing/8.,\\\n",
    "                                color='w', ec='k', zorder=4)\n",
    "    # Add texts\n",
    "            plt.text(x_bias-(v_spacing/8.+0.10*v_spacing+0.01), y_bias, r'$1$', fontsize=15)\n",
    "            ax.add_artist(circle)   \n",
    "    # Edges between nodes\n",
    "    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "        layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.\n",
    "        layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.\n",
    "        for m in xrange(layer_size_a):\n",
    "            print(m)\n",
    "            for o in xrange(layer_size_b):\n",
    "                line = plt.Line2D([n*h_spacing + left, (n + 1)*h_spacing + left],\n",
    "                                  [layer_top_a - m*v_spacing, layer_top_b - o*v_spacing], c='k')\n",
    "                ax.add_artist(line)\n",
    "                xm = (n*h_spacing + left)\n",
    "                xo = ((n + 1)*h_spacing + left)\n",
    "                ym = (layer_top_a - m*v_spacing)\n",
    "                yo = (layer_top_b - o*v_spacing)\n",
    "                rot_mo_rad = np.arctan((yo-ym)/(xo-xm))\n",
    "                rot_mo_deg = rot_mo_rad*180./np.pi\n",
    "                xm1 = xm + (v_spacing/8.+0.05)*np.cos(rot_mo_rad)\n",
    "                if n == 0:\n",
    "                    if yo > ym:\n",
    "                        ym1 = ym + (v_spacing/8.+0.12)*np.sin(rot_mo_rad)\n",
    "                    else:\n",
    "                        ym1 = ym + (v_spacing/8.+0.05)*np.sin(rot_mo_rad)\n",
    "                else:\n",
    "                    if yo > ym:\n",
    "                        ym1 = ym + (v_spacing/8.+0.12)*np.sin(rot_mo_rad)\n",
    "                    else:\n",
    "                        ym1 = ym + (v_spacing/8.+0.04)*np.sin(rot_mo_rad)\n",
    "                plt.text( xm1, ym1,\\\n",
    "                         str(round(coefs_[n][m, o],4)),\\\n",
    "                         rotation = rot_mo_deg, \\\n",
    "                         fontsize = 10)\n",
    "    # Edges between bias and nodes\n",
    "    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "        if n < n_layers-1:\n",
    "            layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.\n",
    "            layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.\n",
    "        for m in xrange(layer_size_a):\n",
    "            x_bias = (n+0.5)*h_spacing + left\n",
    "            y_bias = top + 0.005 \n",
    "        for o in xrange(layer_size_b):\n",
    "            print(o)\n",
    "            line = plt.Line2D([x_bias, (n + 1)*h_spacing + left],\n",
    "                          [y_bias, layer_top_b - o*v_spacing], c='k')\n",
    "            ax.add_artist(line)\n",
    "            xo = ((n + 1)*h_spacing + left)\n",
    "            yo = (layer_top_b - o*v_spacing)\n",
    "            rot_bo_rad = np.arctan((yo-y_bias)/(xo-x_bias))\n",
    "            rot_bo_deg = rot_bo_rad*180./np.pi\n",
    "            xo2 = xo - (v_spacing/8.+0.01)*np.cos(rot_bo_rad)\n",
    "            yo2 = yo - (v_spacing/8.+0.01)*np.sin(rot_bo_rad)\n",
    "            xo1 = xo2 -0.05 *np.cos(rot_bo_rad)\n",
    "            yo1 = yo2 -0.05 *np.sin(rot_bo_rad)\n",
    "            print (\"HERE\")\n",
    "            plt.text( xo1, yo1,\\\n",
    "                 str(round(intercepts_[n][o],4)),\\\n",
    "                 rotation = rot_bo_deg, \\\n",
    "                 fontsize = 10)    \n",
    "    # Output-Arrows\n",
    "    layer_top_0 = v_spacing*(layer_sizes[-1] - 1)/2. + (top + bottom)/2.\n",
    "    for m in xrange(layer_sizes[-1]):\n",
    "        plt.arrow(right+0.015, layer_top_0 - m*v_spacing, 0.16*h_spacing, 0,  lw =1, head_width=0.01, head_length=0.02)\n",
    "    # Record the n_iter_ and loss\n",
    "    plt.text(left + (right-left)/3., bottom - 0.005*v_spacing, \\\n",
    "             'Steps:'+str(n_iter_)+'    Loss: ' + str(round(loss_, 6)), fontsize = 15)\n",
    "    #----------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute 'coefs_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c74a751f6d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m draw_neural_net(ax, .1, .9, .05, .95, [n_units, n_units, n_units, n_units, 1],\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'coefs_'"
     ]
    }
   ],
   "source": [
    "#Visualise Network\n",
    "#From https://gist.github.com/craffel/2d727968c3aaebd10359\n",
    "# from draw_neural_net_ import draw_neural_net\n",
    "\n",
    "fig66 = plt.figure(figsize=(14, 14))\n",
    "ax = fig66.gca()\n",
    "ax.axis('off')\n",
    "\n",
    "draw_neural_net(ax, .1, .9, .05, .95, [n_units, n_units, n_units, n_units, 1],\n",
    "clf.coefs_, \n",
    "clf.intercepts_,\n",
    "clf.n_iter_,\n",
    "clf.loss_,\n",
    "np, plt)\n",
    "plt.savefig(\"neural_network.pdf\", bbox_inches='tight', dpi=1200)\n",
    "plt.show()\n",
    "#========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
