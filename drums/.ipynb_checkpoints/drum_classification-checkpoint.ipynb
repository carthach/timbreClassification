{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import madmom\n",
    "import myutils\n",
    "import collections\n",
    "import subprocess\n",
    "from os.path import basename\n",
    "import librosa\n",
    "\n",
    "from essentia import *\n",
    "from essentia.standard import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/carthach/tmp/drum_timbre/combined/\n",
      "['cymbals', 'perc', 'hats', 'toms', 'claps', 'snares', 'kicks']\n"
     ]
    }
   ],
   "source": [
    "# datasetPath = \"/Users/carthach/tmp/drum_timbre/dataset/\"\n",
    "datasetPath = \"/Users/carthach/tmp/drum_timbre/combined\"\n",
    "\n",
    "#Add Trailing Slash\n",
    "datasetPath = os.path.join(datasetPath, '', '')\n",
    "\n",
    "print datasetPath\n",
    "\n",
    "#Get the timbreClasses in datasetPath\n",
    "timbreClasses = [d for d in os.listdir(datasetPath) if os.path.isdir(os.path.join(datasetPath, d))]\n",
    "\n",
    "instrumentClasses = []\n",
    "\n",
    "# for timbreClass in timbreClasses:\n",
    "#     instrumentPath = datasetPath + timbreClass\n",
    "#     sectionInstrumentClasses = [d for d in os.listdir(instrumentPath) if os.path.isdir(os.path.join(instrumentPath, d))]\n",
    "#     sectionInstrumentClasses = [\"%s/%s\" % (timbreClass, sectionInstrumentClass) for sectionInstrumentClass in sectionInstrumentClasses]\n",
    "    \n",
    "#     instrumentClasses += sectionInstrumentClasses\n",
    "    \n",
    "# print instrumentClasses    \n",
    "\n",
    "print timbreClasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poolToVector(pool):\n",
    "    featureVector = []\n",
    "    \n",
    "    for feature in pool.descriptorNames():\n",
    "        if isinstance(pool[feature], (list, tuple, np.ndarray)):\n",
    "            for featureScalar in pool[feature]:\n",
    "                featureVector.append(featureScalar)\n",
    "        else:\n",
    "            featureVector.append(pool[feature])\n",
    "                                        \n",
    "    return featureVector\n",
    "\n",
    "def savePool(filename, pool):\n",
    "    YamlOutput(filename = filename, writeVersion=False)(pool)\n",
    "    \n",
    "def loadPool(filename):\n",
    "    yamlInput = YamlInput(filename=filename)\n",
    "    \n",
    "    pool = yamlInput()\n",
    "    \n",
    "    return pool\n",
    "\n",
    "def extractFeatures(filename):\n",
    "    audio, sampleRate = librosa.load(filename, sr=44100)\n",
    "#     audio, sampleRate = loadAudio(filename)\n",
    "\n",
    "    # create the pool and the necessary algorithms\n",
    "    pool = Pool()\n",
    "    w = Windowing()\n",
    "    spec = Spectrum()\n",
    "    centroid = Centroid(range=22050)\n",
    "    flatness = Flatness()\n",
    "    flatnessDB = FlatnessDB()\n",
    "    mfcc = MFCC()\n",
    "    bfcc = BFCC(\n",
    "        type = 'power',\n",
    "        weighting = 'linear',\n",
    "        lowFrequencyBound = 0,\n",
    "        highFrequencyBound = 22050,\n",
    "#         highFrequencyBound = 8000,        \n",
    "        numberBands = 26,\n",
    "        numberCoefficients = 13,\n",
    "        normalize = 'unit_max',\n",
    "        dctType = 3,\n",
    "        liftering = 22\n",
    "    )\n",
    "    loudness = Loudness()\n",
    "    logAttackTime = LogAttackTime()\n",
    "        \n",
    "    # compute the centroid for all frames in our audio and add it to the pool\n",
    "    for frame in FrameGenerator(audio, frameSize = 1024, hopSize = 512):        \n",
    "        s = spec(w(frame))\n",
    "        \n",
    "        c = centroid(s)\n",
    "        pool.add('centroid', c)\n",
    "        \n",
    "#         f = flatness(s)\n",
    "        f = flatnessDB(s)        \n",
    "        pool.add('flatness', f)        \n",
    "\n",
    "        m_bands, m_coeffs = mfcc(s)\n",
    "        pool.add('mfcc', m_coeffs)\n",
    "        \n",
    "        b_bands, b_coeffs = bfcc(s)\n",
    "        pool.add('bfcc', b_coeffs)\n",
    "        \n",
    "    # aggregate the results\n",
    "    aggrPool = PoolAggregator(defaultStats = [ 'mean', 'var'])(pool)\n",
    "    \n",
    "    l, aStart, aStop = logAttackTime(audio)\n",
    "    aggrPool.add('logAttackTime', l)\n",
    "    aggrPool.add('loudness', loudness(audio))\n",
    "    \n",
    "    return aggrPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def analyseSounds(datasetPath, soundClasses, reAnalyse=False, featureSet=[]):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for soundClass in soundClasses:\n",
    "        soundPath = datasetPath + soundClass\n",
    "\n",
    "        soundFiles = myutils.getListOfFilesRecursive(soundPath, \"*.wav\")\n",
    "            \n",
    "        print \"Processing: %s\" % soundClass\n",
    "    \n",
    "        for soundFile in soundFiles:\n",
    "            yamlFile = soundFile + \".yaml\"\n",
    "            \n",
    "            #Analyse or retrieve yaml features\n",
    "            if not os.path.isfile(yamlFile) or reAnalyse:            \n",
    "                featurePool = extractFeatures(soundFile)\n",
    "                savePool(yamlFile, featurePool)\n",
    "            else:        \n",
    "                featurePool = loadPool(yamlFile)\n",
    "                \n",
    "            for descriptor in featurePool.descriptorNames():\n",
    "                if descriptor not in featureSet:\n",
    "                    featurePool.remove(descriptor)\n",
    "                                                        \n",
    "            featureVector = poolToVector(featurePool)\n",
    "                    \n",
    "#             print featureVector\n",
    "#             print(\"\\n*********************\")\n",
    "                    \n",
    "#             timbreFeatureDict[timbreClass][timbreClassFile] = features\n",
    "\n",
    "            features.append(featureVector)\n",
    "            labels.append(soundClasses.index(soundClass))  \n",
    "        \n",
    "#             print \"\\t%s\" % soundFile\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "temporalFeatures = [\"loudness\", \"logAttackTime\"]\n",
    "spectralFeatures = [\"centroid.mean\", \"centroid.var\", \"flatness.mean\", \"flatness.var\"]\n",
    "mfccFeatures = [\"mfcc.mean\", \"mfcc.var\"]\n",
    "bfccFeatures = [\"bfcc.mean\", \"bfcc.var\"]\n",
    "temporalSpectralFeatures = temporalFeatures + spectralFeatures\n",
    "mfccTemporalSpectralFeatures = mfccFeatures + temporalSpectralFeatures\n",
    "bfccTemporalSpectralFeatures = bfccFeatures + temporalSpectralFeatures\n",
    "\n",
    "featureSets = {\n",
    "    \"Temporal\" : temporalFeatures,\n",
    "    \"Spectral\" : spectralFeatures,\n",
    "    \"Temporal+Spectral\" : temporalSpectralFeatures,\n",
    "    \"MFCC\" : mfccFeatures,\n",
    "    \"BFCC\" : bfccFeatures,\n",
    "    \"MFCC+Temporal+Spectral\" : mfccTemporalSpectralFeatures,\n",
    "    \"BFCC+Temporal+Spectral\" : bfccTemporalSpectralFeatures\n",
    "}\n",
    "\n",
    "# features, labels = analyseSounds(datasetPath, instrumentClasses, reAnalyse=True, featureSet=featureSet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Spectral\n",
      "/Users/carthach/tmp/drum_timbre/combined/\n",
      "Processing: cymbals\n",
      "Processing: perc\n",
      "Processing: hats\n",
      "Processing: toms\n",
      "Processing: claps\n",
      "Processing: snares\n",
      "Processing: kicks\n",
      "Classifying with: kNN\n",
      "0.62 (+/- 0.11)\n",
      "Classifying with: SVM\n",
      "0.57 (+/- 0.09)\n",
      "Classifying with: ANN\n",
      "0.61 (+/- 0.09)\n",
      "Evaluating: MFCC\n",
      "/Users/carthach/tmp/drum_timbre/combined/\n",
      "Processing: cymbals\n",
      "Processing: perc\n",
      "Processing: hats\n",
      "Processing: toms\n",
      "Processing: claps\n",
      "Processing: snares\n",
      "Processing: kicks\n",
      "Classifying with: kNN\n",
      "0.84 (+/- 0.09)\n",
      "Classifying with: SVM\n",
      "0.83 (+/- 0.09)\n",
      "Classifying with: ANN\n",
      "0.85 (+/- 0.10)\n",
      "Evaluating: Temporal\n",
      "/Users/carthach/tmp/drum_timbre/combined/\n",
      "Processing: cymbals\n",
      "Processing: perc\n",
      "Processing: hats\n",
      "Processing: toms\n",
      "Processing: claps\n",
      "Processing: snares\n",
      "Processing: kicks\n",
      "Classifying with: kNN\n",
      "0.39 (+/- 0.12)\n",
      "Classifying with: SVM\n",
      "0.41 (+/- 0.09)\n",
      "Classifying with: ANN\n",
      "0.47 (+/- 0.10)\n",
      "Evaluating: BFCC+Temporal+Spectral\n",
      "/Users/carthach/tmp/drum_timbre/combined/\n",
      "Processing: cymbals\n",
      "Processing: perc\n",
      "Processing: hats\n",
      "Processing: toms\n",
      "Processing: claps\n",
      "Processing: snares\n",
      "Processing: kicks\n",
      "Classifying with: kNN\n",
      "0.86 (+/- 0.09)\n",
      "Classifying with: SVM\n",
      "0.86 (+/- 0.07)\n",
      "Classifying with: ANN\n",
      "0.86 (+/- 0.08)\n",
      "Evaluating: BFCC\n",
      "/Users/carthach/tmp/drum_timbre/combined/\n",
      "Processing: cymbals\n",
      "Processing: perc\n",
      "Processing: hats\n",
      "Processing: toms\n",
      "Processing: claps\n",
      "Processing: snares\n",
      "Processing: kicks\n",
      "Classifying with: kNN\n",
      "0.86 (+/- 0.09)\n",
      "Classifying with: SVM\n",
      "0.85 (+/- 0.09)\n",
      "Classifying with: ANN\n",
      "0.85 (+/- 0.12)\n",
      "Evaluating: MFCC+Temporal+Spectral\n",
      "/Users/carthach/tmp/drum_timbre/combined/\n",
      "Processing: cymbals\n",
      "Processing: perc\n",
      "Processing: hats\n",
      "Processing: toms\n",
      "Processing: claps\n",
      "Processing: snares\n",
      "Processing: kicks\n",
      "Classifying with: kNN\n",
      "0.83 (+/- 0.08)\n",
      "Classifying with: SVM\n",
      "0.84 (+/- 0.07)\n",
      "Classifying with: ANN\n",
      "0.85 (+/- 0.07)\n",
      "Evaluating: Temporal+Spectral\n",
      "/Users/carthach/tmp/drum_timbre/combined/\n",
      "Processing: cymbals\n",
      "Processing: perc\n",
      "Processing: hats\n",
      "Processing: toms\n",
      "Processing: claps\n",
      "Processing: snares\n",
      "Processing: kicks\n",
      "Classifying with: kNN\n",
      "0.67 (+/- 0.11)\n",
      "Classifying with: SVM\n",
      "0.60 (+/- 0.10)\n",
      "Classifying with: ANN\n",
      "0.70 (+/- 0.10)\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import csv\n",
    "\n",
    "#Select this to true if you want to analyse on the first iteration\n",
    "reAnalyse = True\n",
    "\n",
    "with open('results.csv', 'wb') as csvfile:\n",
    "    resultswriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    resultswriter.writerow([\"\", \"kNN\", \"SVM\", \"ANN\"])    \n",
    "    \n",
    "    for featureSetName, featureSet in featureSets.iteritems():\n",
    "        print(\"Evaluating: %s\" % featureSetName)\n",
    "        \n",
    "        print datasetPath\n",
    "        \n",
    "        features, labels = analyseSounds(datasetPath, timbreClasses, reAnalyse=reAnalyse, featureSet=featureSet)\n",
    "#         features, labels = analyseSounds(datasetPath, instrumentClasses, reAnalyse=reAnalyse, featureSet=featureSet)        \n",
    "\n",
    "        if reAnalyse:\n",
    "            reAnalyse = False\n",
    "        \n",
    "    #     print features\n",
    "\n",
    "\n",
    "\n",
    "        classifierNames = [\"kNN\", \"SVM\", \"ANN\"]\n",
    "\n",
    "        classifiers = [KNeighborsClassifier(1),\n",
    "                       SVC(gamma=0.1, C=100.),\n",
    "                       MLPClassifier(max_iter=500)\n",
    "                      ]\n",
    "        \n",
    "        results = []\n",
    "\n",
    "        # iterate over classifiers        \n",
    "        for classifierName, clf in zip(classifierNames, classifiers):\n",
    "            if classifierName == \"ANN\":\n",
    "                scaler = StandardScaler()\n",
    "            else:\n",
    "                scaler = MinMaxScaler()\n",
    "                \n",
    "            features = scaler.fit_transform(features)\n",
    "\n",
    "            n_samples = len(features)\n",
    "            n_features = len(features[0])\n",
    "            n_units = n_features\n",
    "            \n",
    "            print(\"Classifying with: %s\" % classifierName)\n",
    "            scores = cross_val_score(clf, features, labels, cv=10)\n",
    "            result = \"%0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)\n",
    "            print(result)\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        resultswriter.writerow([featureSetName, results[0], results[1], results[2]])\n",
    "        \n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute 'coefs_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c74a751f6d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m draw_neural_net(ax, .1, .9, .05, .95, [n_units, n_units, n_units, n_units, 1],\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'coefs_'"
     ]
    }
   ],
   "source": [
    "#Visualise Network\n",
    "#From https://gist.github.com/craffel/2d727968c3aaebd10359\n",
    "# from draw_neural_net_ import draw_neural_net\n",
    "\n",
    "fig66 = plt.figure(figsize=(14, 14))\n",
    "ax = fig66.gca()\n",
    "ax.axis('off')\n",
    "\n",
    "draw_neural_net(ax, .1, .9, .05, .95, [n_units, n_units, n_units, n_units, 1],\n",
    "clf.coefs_, \n",
    "clf.intercepts_,\n",
    "clf.n_iter_,\n",
    "clf.loss_,\n",
    "np, plt)\n",
    "plt.savefig(\"neural_network.pdf\", bbox_inches='tight', dpi=1200)\n",
    "plt.show()\n",
    "#========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
